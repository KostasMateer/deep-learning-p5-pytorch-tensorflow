{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad858d46-f774-4515-bb28-fea50362acc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import scipy.io as sio\n",
    "import numpy\n",
    "import numpy as np\n",
    "import scipy.io as sci\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "from torchvision import transforms as T\n",
    "from torchvision.transforms import functional as F\n",
    "import torch as T\n",
    "from torchvision import datasets\n",
    "import torch.utils as utils\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64e6b35-6fa7-474e-85a9-cc1c39d5cfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244d3b2f-0113-4872-bee7-2cf504538544",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2384edad-fde1-4778-abe3-69a10e89b2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1935182-bed3-41c2-a8b2-5d663cda4333",
   "metadata": {},
   "source": [
    "KMNIST references:\n",
    "* [GitHub page](https://github.com/rois-codh/kmnist)\n",
    "* [research paper](https://arxiv.org/pdf/1812.01718.pdf)\n",
    "\n",
    "EMNIST references:\n",
    "* [NIST page](https://www.nist.gov/itl/products-and-services/emnist-dataset)\n",
    "* [research paper](https://arxiv.org/pdf/1702.05373v1.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2cbf6fb-a5b8-4244-afe9-ec852ac4d46e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kmnist', 'NLP', 'chest_xrays', 'brain_scans', 'birds', 'emnist']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os import listdir as ls\n",
    "ls(\"/home/DAVIDSON/brwiedenbeck/public\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0de8518a-dad3-43ea-8ab9-aede2c218e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "#loads device \n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "478db6d7-28ff-47de-a2ee-34a1cb1b71bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "mat = sci.loadmat(\"/home/DAVIDSON/brwiedenbeck/public/emnist/emnist-balanced.mat\")\n",
    "\n",
    "\n",
    "data = mat['dataset']\n",
    "x_train = data['train'][0,0]['images'][0,0]/255\n",
    "y_train = data['train'][0,0]['labels'][0,0]\n",
    "x_test =  data['test'][0,0]['images'][0,0]/255\n",
    "y_test =  data['test'][0,0]['labels'][0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcbd1871-c28c-4b89-ae02-2a236627d1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to tensor\n",
    "x_Train = T.tensor(x_train,\n",
    "      dtype=T.float32).to(device)\n",
    "y_Train = T.tensor(y_train,\n",
    "      dtype=T.long).to(device)\n",
    "x_Test = T.tensor(x_test,\n",
    "      dtype=T.float32).to(device)\n",
    "y_Test = T.tensor(y_test,\n",
    "      dtype=T.long).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f44bb9c9-6b68-40c0-93da-0e06db84fd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshape to 1D\n",
    "y_Train = y_Train.reshape([112800])\n",
    "y_Test = y_Test.reshape([18800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c2c7c4c-2dd7-4e54-a18c-0f492b02d73d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([112800])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_Train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ab90b44-2ac0-45d1-be5c-7df30d9c40c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one_hot_encoding\n",
    "y_Train = torch.nn.functional.one_hot(y_Train)\n",
    "y_Test = torch.nn.functional.one_hot(y_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cfe57c8-0b72-4a75-a345-fede22542f93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([112800, 47])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_Train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ffd7e6c-a04d-4b17-a970-1e75eb9562a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine train label and image dataset\n",
    "train_dataset = utils.data.TensorDataset(x_Train, y_Train)\n",
    "test_dataset = utils.data.TensorDataset(x_Test, y_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0eaeda8d-eef5-46af-89eb-484ed3998de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set size: <torch.utils.data.dataset.Subset object at 0x153b668d4670>, validation set size: <torch.utils.data.dataset.Subset object at 0x153b666c34f0>\n"
     ]
    }
   ],
   "source": [
    "#split train and validation data set\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset_dl, val_dataset_dl = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
    "print(f'train set size: {train_dataset_dl}, validation set size: {val_dataset_dl}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5d39132-8eba-42e9-87e5-ae648c8b6a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "batch_size = 5\n",
    "train_dataset_b = torch.utils.data.DataLoader(train_dataset_dl, batch_size=batch_size, shuffle=True)\n",
    "test_dataset_b = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataset_b = torch.utils.data.DataLoader(val_dataset_dl, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bc64fb4e-0ab0-4b03-a1bc-697a8836f6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=800, bias=True)\n",
      "    (3): Linear(in_features=800, out_features=800, bias=True)\n",
      "    (4): Linear(in_features=800, out_features=800, bias=True)\n",
      "    (5): Linear(in_features=800, out_features=800, bias=True)\n",
      "    (6): Linear(in_features=800, out_features=512, bias=True)\n",
      "    (7): Dropout(p=0.2, inplace=False)\n",
      "    (8): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (9): ReLU()\n",
      "    (10): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (11): Dropout(p=0.2, inplace=False)\n",
      "    (12): Linear(in_features=512, out_features=47, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 800),\n",
    "            nn.Linear(800, 800),\n",
    "            nn.Linear(800, 800),\n",
    "            nn.Linear(800, 800),\n",
    "            nn.Linear(800, 512),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(512, 47)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b66b7fe5-48d7-4b45-93be-a34254d23071",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizing the model\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "aec8c14d-a491-4bbc-b508-0277ad549407",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "def train(train_dataset_b, model, loss_fn, optimizer):\n",
    "    size = len(train_dataset_b.dataset)\n",
    "    model.train()\n",
    "    for i, (images, labels) in enumerate(train_dataset_b):\n",
    "        # Compute prediction error\n",
    "        pred = model(images)\n",
    "        loss = loss_fn(pred, labels.float())\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_size % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(images)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\") \n",
    "    \n",
    "    valid_loss = 0.0 \n",
    "    model.eval()     \n",
    "    for images, labels in val_dataset_b:\n",
    "        if torch.cuda.is_available():\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "        pred = model(images)\n",
    "        loss = loss_fn(pred, labels.float())\n",
    "        valid_loss = loss.item()\n",
    "    print(f'\\t\\t Training Loss: {loss/len(train_dataset_b.dataset)} \\t\\t Validation Loss: {valid_loss / len(val_dataset_b.dataset)}')\n",
    "    train_loss_values = loss/len(train_dataset_b.dataset)\n",
    "    train_loss = train_loss_values.item()\n",
    "    train_losses.append(train_loss)   \n",
    "    val_losses.append(valid_loss/len(val_dataset_b.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "830a5018-66f4-478e-9876-c26f6a3c4d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t Training Loss: 2.2665075448458083e-05 \t\t Validation Loss: 9.066030277428052e-05\n"
     ]
    }
   ],
   "source": [
    "train(train_dataset_b, model, loss_fn, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a9356810-04e6-4be1-b852-1e7189db91b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_losses = []\n",
    "test_accuracy=[]\n",
    "def test(test_dataset_b, model, loss_fn):\n",
    "    size = len(test_dataset_b.dataset)\n",
    "    num_batches = len(test_dataset_b)\n",
    "     \n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate (test_dataset_b):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            pred = model(images)\n",
    "            test_loss += loss_fn(pred, labels.float()).item()\n",
    "            correct += (pred.argmax(1) == labels.argmax(1)).type(torch.float).sum().item()\n",
    "            \n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    test_accuracy.append(100*correct)\n",
    "    test_losses.append(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "87c26608-59e0-47db-a69a-a6ba84ad34fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 56.9%, Avg loss: 1.358505 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(test_dataset_b, model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f9b5c5b3-8867-4aae-bc67-3f9a88db089a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "\t\t Training Loss: 7.3462365435261745e-06 \t\t Validation Loss: 2.9384947203575298e-05\n",
      "Test Error: \n",
      " Accuracy: 73.9%, Avg loss: 0.794009 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "\t\t Training Loss: 2.8990316423005424e-06 \t\t Validation Loss: 1.1596127234874887e-05\n",
      "Test Error: \n",
      " Accuracy: 77.2%, Avg loss: 0.696051 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "\t\t Training Loss: 2.9321490728762e-06 \t\t Validation Loss: 1.172859697265828e-05\n",
      "Test Error: \n",
      " Accuracy: 77.7%, Avg loss: 0.651907 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "\t\t Training Loss: 2.8321264835540205e-06 \t\t Validation Loss: 1.1328506078703184e-05\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.628143 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "\t\t Training Loss: 5.116264219395816e-06 \t\t Validation Loss: 2.0465056629891092e-05\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.595192 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "\t\t Training Loss: 3.572298055587453e-06 \t\t Validation Loss: 1.4289192432630147e-05\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.589964 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "\t\t Training Loss: 1.7136530914285686e-06 \t\t Validation Loss: 6.854612750153169e-06\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.556989 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "\t\t Training Loss: 2.7205053356738063e-06 \t\t Validation Loss: 1.0882021449770488e-05\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.598974 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "\t\t Training Loss: 4.141074441577075e-06 \t\t Validation Loss: 1.6564298553246977e-05\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.585338 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "\t\t Training Loss: 2.2541435100720264e-06 \t\t Validation Loss: 9.016574406666113e-06\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.597616 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataset_b, model, loss_fn, optimizer)\n",
    "    test(test_dataset_b, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
